server:
  port: 84

log:
  app-name: user-service

kafka-config:
  bootstrap-servers: localhost:19092, localhost:29092, localhost:39092
  schema-registry-url-key: schema.registry.url
  schema-registry-url: http://localhost:8081
  topic-name: USER_REGISTER_KAFKA_TOPIC
  topic-names-to-create:
    - USER_REGISTER_KAFKA_TOPIC
  numOfPartitions: 2
  replicationFactor: 3

userRegisterKafkaTopic: USER_REGISTER_KAFKA_TOPIC

spring:
  zipkin:
    base-url: http://localhost:9411/
    sender:
      type: web
    enabled: true
    locator:
      discovery:
        enabled: true
    discovery-client-enabled: true
    service:
      name: user-service
  rabbitmq:
    host: localhost
    port: 5672
    username: guest
    password: guest
    template:
      retry:
        max-attempts: 1
        enabled: true
      exchange: userExchange
      routing-key: "routing-user"
      default-receive-queue: "queue-user"
    listener:
      simple:
        retry:
          max-attempts: 3
      direct:
        retry:
          max-attempts: 3
  redis:
    host: localhost
    port: 6379
  data:
    r2dbc:
      repositories:
        enabled: true

  r2dbc:
    url: r2dbc:postgresql://user:password@localhost:5432/user
  main:
    allow-bean-definition-overriding: true
  application:
    name: user-service
  kafka:
    bootstrap-servers: http://localhost:19092, http://localhost:29092, http://localhost:39092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
#      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    #    consumer:
    #      group-id: kafka-to-elastic-service
    #      auto-offset-reset: earliest
    #      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    #      value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
    properties:
      schema.registry.url: http://localhost:8081
  profiles:
    active: local

retry-config:
  initialIntervalMs: 1000
  maxIntervalMs: 10000
  multiplier: 2.0
  maxAttempts: 3
  sleepTimeMs: 2000

management:
  endpoints:
    web:
      base-path: /actuator
      exposure.include: health, prometheus, gateway
      path-mapping.prometheus: metrics
  endpoint:
    health:
      show-details: always
    prometheus:
      cache.time-to-live: 1ms
    gateway:
      enabled: true

eureka:
  client:
    serviceUrl:
      defaultZone: http://localhost:8761/eureka/
  instance:
    lease-expiration-duration-in-seconds: 5
    lease-renewal-interval-in-seconds: 2

logging:
  level:
    ROOT: INFO
    com.netflix.eureka: OFF
    com.netflix.discovery: OFF

logstash:
  host: localhost
  port: 5000

kafka-producer-config:
  key-serializer-class: org.apache.kafka.common.serialization.LongSerializer
  value-serializer-class: io.confluent.kafka.serializers.KafkaAvroSerializer
  compression-type: snappy
  acks: all
  batch-size: 16384
  batch-size-boost-factor: 100
  linger-ms: 5
  request-timeout-ms: 60000
  retry-count: 5

config:
  cors:
    mapping: /**
    methods: GET, POST, DELETE, PUT
    allowedCredentials: true
    origins: http://localhost:3001
    allowedHeaders:
      Content-Type, content-type, x-requested-with,
      Access-Control-Allow-Origin,
      Access-Control-Allow-Credentials,
      Access-Control-Allow-Headers,
      x-auth-token, x-app-id, Origin, Accept,
      X-Requested-With, Access-Control-Request-Method,
      Access-Control-Request-Headers, Authorization,
      Set-Cookie, Cookie
    exposedHeaders:
      Authorization, set-cookie